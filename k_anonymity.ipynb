{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-identification and De-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Useful display function for dataframe\n",
    "\"\"\"\n",
    "def display_df(df, nrows=10, ncols=None):\n",
    "    with pd.option_context('display.max_rows', nrows, 'display.max_columns', ncols):\n",
    "        display (df)\n",
    "        \n",
    "def print_row(df, row):\n",
    "    for ctr,i in enumerate(df.iloc[row]):\n",
    "        print (str(df.columns[ctr])+\": \"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#whole unaltered dataset\n",
    "df_raw = pd.read_csv(\"../mid_sample_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Unnecessary Fields and Clean NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads configuration file, a list of strings seperated by new lines, and returns a list\n",
    "\"\"\"\n",
    "def read_config(file):\n",
    "    with open(file) as f:\n",
    "        config_list = [(l) for l in f.read().split()]\n",
    "    f.close()\n",
    "    return config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "qis = read_config('config.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to keep the `user_id` as a key, the quasi-identifiers, the `completed` field to find the completion rate, `explored` to find the exploration rate, and `grade` for the discussion of L-diversity in question 6. Everything else can be dropped. Then we can clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_raw[['user_id'] + qis + ['completed', 'explored', 'grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the fields contain NaNs when they actually should contain 0. We will replace those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes list of fields with NaNs and fills NaN values with fill_val. Does this inplace.\n",
    "\"\"\"\n",
    "def replace_NaNs(df, labels, fill_val):\n",
    "    for label in labels:\n",
    "        df[label].fillna(fill_val, inplace=True)\n",
    "\"\"\"\n",
    "Gets ratio of NaNs for each column\n",
    "\"\"\"\n",
    "def stats_NaN(df):\n",
    "    df_stats = pd.DataFrame(index=[df.columns], columns=[\"NaN Ratio\"])\n",
    "    for col in df.columns:\n",
    "        df_stats[\"NaN Ratio\"][col] = df[col].isna().sum()/len(df) #NaN ratio\n",
    "    return df_stats.sort_values(by=['NaN Ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completed</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>0.110371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countryLabel</th>\n",
       "      <td>0.111971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc_by_ip</th>\n",
       "      <td>0.112171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.131326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoE</th>\n",
       "      <td>0.139956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YoB</th>\n",
       "      <td>0.150226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_events</th>\n",
       "      <td>0.184851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0.225491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdivision</th>\n",
       "      <td>0.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>0.258136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grade</th>\n",
       "      <td>0.272366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explored</th>\n",
       "      <td>0.477072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postalCode</th>\n",
       "      <td>0.581953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_posts</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_votes</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_threads</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_comments</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nforum_pinned</th>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NaN Ratio\n",
       "user_id                 0\n",
       "completed               0\n",
       "continent        0.110371\n",
       "countryLabel     0.111971\n",
       "cc_by_ip         0.112171\n",
       "gender           0.131326\n",
       "LoE              0.139956\n",
       "YoB              0.150226\n",
       "nforum_events    0.184851\n",
       "city             0.225491\n",
       "subdivision      0.242641\n",
       "region           0.258136\n",
       "grade            0.272366\n",
       "explored         0.477072\n",
       "postalCode       0.581953\n",
       "nforum_posts       0.9603\n",
       "nforum_votes       0.9603\n",
       "nforum_endorsed    0.9603\n",
       "nforum_threads     0.9603\n",
       "nforum_comments    0.9603\n",
       "nforum_pinned      0.9603"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_NaN(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "NaN_to_0_fields = ['YoB', 'postalCode', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', \n",
    "                   'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events',\n",
    "                  'explored']\n",
    "replace_NaNs(df_clean, NaN_to_0_fields, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#cast to numeric type\n",
    "df_clean['explored'] = pd.to_numeric(df_clean['explored'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Useful Statistical Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_clean.sort_values('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In k-anonymizing a dataset, records will be compressed together. Therefire, we must preserve valuable statistics like the completion rate, which means we must create new columns `nStarted` and `nCompleted` which keeps track of the amount of classes started and completed respectively by a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.join(pd.DataFrame(df_clean.groupby('user_id').size(), \n",
    "                                      columns=['nStarted']),\n",
    "                         on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.join(pd.DataFrame(df_clean[df_clean['completed']==True].groupby(['user_id']).size(), \n",
    "                                      columns=['nCompleted']),\n",
    "                   on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.join(pd.DataFrame(df_clean[df_clean['explored']==True].groupby(['user_id']).size(), \n",
    "                                      columns=['nExplored']),\n",
    "                   on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix NaNs\n",
    "replace_NaNs(df_clean, ['nCompleted','nExplored','grade'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop `completed` and `explored` as it is no longer necessary in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['completed','explored'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Completion Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write a generalizable function that finds the completion rate of a dataset. It will use the `nStarted` and `nCompleted` columns to tabulate this. It will be general enough to use on the clean dataset without double counting and also able to handle the k-anonymized datasets where we have already handled duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns completion rate and exploration rate of a dataframe. If user_id is present,\n",
    "function counts per unique_id to avoid double counting. Otherwise assumes that\n",
    "duplicates have been handled if user_id is dropped. Returns list. First element is \n",
    "completion rate, second element is exploration rate.\n",
    "\"\"\"\n",
    "def getStats(df):\n",
    "    if 'user_id' in df.columns:\n",
    "        df = df[['user_id', 'nStarted', 'nExplored', 'nCompleted']]\n",
    "        df.drop_duplicates(subset='user_id', inplace=True)\n",
    "    start_sum = df['nStarted'].sum()\n",
    "    exp_sum = df['nExplored'].sum()\n",
    "    comp_sum = df['nCompleted'].sum()\n",
    "    return [float(comp_sum)/start_sum,float(exp_sum)/start_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to check k-anonymity for unit testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKAnon(df, qis):\n",
    "    return min(df.groupby(qis).size())\n",
    "\"\"\"\n",
    "Checks whether k-anonymity of dataset meets threshold. We use this to test whether a \n",
    "database is the required k-anonymity. If dataset is empty, it returns True.\n",
    "\"\"\"\n",
    "def checkKAnon(df, qis, k):\n",
    "    return (len(df)==0) or (getKAnon(df,qis)>=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a general function that takes a dataframe, a list of quasi-identifiers, and a value `k`. The dataframe must be prepped with the `nStarted`, `nCompleted`, and `nExplored` fields to maintain analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a df where under less than k same quasi-identier samples are suppressed, making\n",
    "the df k-anonymous.\n",
    "\"\"\"\n",
    "def suppressKAnon(df, qis, k=5):\n",
    "    df_drop = df.drop_duplicates(subset=['user_id']+qis)\n",
    "    #sum completion statistics and count unique_ids (k) for set of qis\n",
    "    df_kanon = df_drop.groupby(qis).agg(\n",
    "        {'nStarted':'sum','nCompleted':'sum','nExplored':'sum',\n",
    "         'grade':(lambda x:len(set(x))) ,'user_id':'nunique'}).reset_index()\n",
    "    df_kanon = df_kanon.rename(columns={'user_id' : 'k', 'grade':'l_grades'})\n",
    "    df_kanon = df_kanon[df_kanon['k'] >= k] #suppresses less than k samples\n",
    "    \n",
    "    #print statistics\n",
    "    stats = getStats(df_kanon)\n",
    "    cr_anon = stats[0]\n",
    "    er_anon = stats[1]\n",
    "    print(str(k)+\"-anon dataset completion rate: %.3f%%\"%(cr_anon*100))\n",
    "    print(str(k)+\"-anon dataset exploration rate: %.3f%%\"%(er_anon*100))\n",
    "    \n",
    "    #now must re-add records based on k\n",
    "    df_kanon = pd.DataFrame(np.repeat(df_kanon.values,df_kanon['k'].values,\n",
    "                                     axis=0), columns=df_kanon.columns)\n",
    "    \n",
    "    #must drop k, nStarted, nCompleted, and nExplored fields as these are artifacts of\n",
    "    #completion analysis\n",
    "    df_kanon = df_kanon.drop(columns=['k','nStarted','nCompleted','nExplored'])\n",
    "    \n",
    "    #print number of records suppresses\n",
    "    records_suppressed = len(df)-len(df_kanon)\n",
    "    print(str(records_suppressed)+\" records suppressed for k=\"+str(k))\n",
    "    return df_kanon.sort_values(by=qis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "clean_stats = getStats(df_clean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset completion rate: 2.777%\n",
      "Clean dataset exploration rate: 13.430%\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean dataset completion rate: %.3f%%\"%(clean_stats[0]*100))\n",
    "print(\"Clean dataset exploration rate: %.3f%%\"%(clean_stats[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-anon dataset completion rate: 1.279%\n",
      "3-anon dataset exploration rate: 10.638%\n",
      "183150 records suppressed for k=3\n"
     ]
    }
   ],
   "source": [
    "df_3supp = suppressKAnon(df_clean, qis, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(getKAnon(df_3supp,qis)>=3), \"k-anonymity only \"+str(getKAnon(df_3supp,qis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-anon dataset completion rate: 1.210%\n",
      "4-anon dataset exploration rate: 10.388%\n",
      "187797 records suppressed for k=4\n"
     ]
    }
   ],
   "source": [
    "df_4supp = suppressKAnon(df_clean, qis, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(getKAnon(df_4supp,qis)>=4), \"k-anonymity only \"+str(getKAnon(df_4supp,qis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-anon dataset completion rate: 1.214%\n",
      "5-anon dataset exploration rate: 10.275%\n",
      "190473 records suppressed for k=5\n"
     ]
    }
   ],
   "source": [
    "df_5supp = suppressKAnon(df_clean, qis, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(getKAnon(df_5supp,qis)>=5), \"k-anonymity only \"+str(getKAnon(df_5supp,qis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntheticKAnon(df, qis, k=5):\n",
    "    #drops duplicates to avoid double counting for the completion rate\n",
    "    df_drop = df.drop_duplicates(subset=['user_id']+qis)\n",
    "    #sum completion statistics and count unique_ids (k) for set of qis\n",
    "    df_kanon = df_drop.groupby(qis).agg({'nStarted':'sum','nCompleted':'sum', \n",
    "                                    'nExplored':'sum','user_id':'nunique'}).reset_index()\n",
    "    df_kanon = df_kanon.rename(columns={'user_id' : 'k'})\n",
    "    \n",
    "    df_add_synth = df_kanon[df_kanon['k'] < k] #df to add records to\n",
    "    df_kanon = df_kanon[df_kanon['k']>=k] #df with >= k\n",
    "    \n",
    "    #still must re-add records based on k values in like in suppression function\n",
    "    df_kanon = pd.DataFrame(np.repeat(df_kanon.values,df_kanon['k'].values,\n",
    "                                     axis=0), columns=df_kanon.columns)\n",
    "    \n",
    "    #add synthetic records based on k\n",
    "    df_add_synth = pd.DataFrame(np.repeat(df_add_synth.values,\n",
    "                                          k, \n",
    "                                     axis=0), columns=df_add_synth.columns)\n",
    "    \n",
    "    df_kanon = df_kanon.append(df_add_synth, ignore_index=True) #combine datasets\n",
    "    \n",
    "    #print statistics\n",
    "    stats = getStats(df_kanon)\n",
    "    cr_anon = stats[0]\n",
    "    er_anon = stats[1]\n",
    "    print(str(k)+\"-anon dataset completion rate: %.3f%%\"%(cr_anon*100))\n",
    "    print(str(k)+\"-anon dataset exploration rate: %.3f%%\"%(er_anon*100))\n",
    "    \n",
    "    #must drop k, nStarted, nCompleted, and nExplored fields as these are artifacts\n",
    "    #of completion analysis\n",
    "    df_kanon = df_kanon.drop(columns=['k','nStarted','nCompleted','nExplored'])\n",
    "    \n",
    "    #print number of records added\n",
    "    records_added = len(df_kanon)-len(df)\n",
    "    print(str(records_added)+\" records added for k=\"+str(k))\n",
    "    \n",
    "    return df_kanon.sort_values(by=qis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-anon dataset completion rate: 3.229%\n",
      "3-anon dataset exploration rate: 14.430%\n",
      "116715 records added for k=3\n"
     ]
    }
   ],
   "source": [
    "df_3synth = syntheticKAnon(df_clean, qis, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(getKAnon(df_3synth,qis)==3), \"k-anonymity only \"+str(getKAnon(df_5synth,qis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-anon dataset completion rate: 3.358%\n",
      "4-anon dataset exploration rate: 14.682%\n",
      "218219 records added for k=4\n"
     ]
    }
   ],
   "source": [
    "df_4synth = syntheticKAnon(df_clean, qis, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(getKAnon(df_4synth,qis)==4), \"k-anonymity only \"+str(getKAnon(df_4synth,qis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-anon dataset completion rate: 3.434%\n",
      "5-anon dataset exploration rate: 14.832%\n",
      "320392 records added for k=5\n"
     ]
    }
   ],
   "source": [
    "df_5synth = syntheticKAnon(df_clean, qis, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(checkKAnon(df_5synth, qis, 5)), \"k-anonymity only \"+str(getKAnon(df_5synth,qis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization, Blurring, and Suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Bins for Continous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas qcut has very useful binning functionality. We play around with qs parameter to sufficiently generalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1960.0], (1973.0, 1980.0], (1984.0, 1987.0], (1980.0, 1984.0], (1990.0, 1992.0], (1960.0, 1973.0], (1992.0, 1995.0], (1987.0, 1990.0], (1995.0, 2018.0]]\n",
       "Categories (9, interval[float64]): [(-0.001, 1960.0] < (1960.0, 1973.0] < (1973.0, 1980.0] < (1980.0, 1984.0] ... (1987.0, 1990.0] < (1990.0, 1992.0] < (1992.0, 1995.0] < (1995.0, 2018.0]]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['YoB'],10, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1.0], (2.0, 4.0], (4.0, 10.0], (1.0, 2.0], (10.0, 465.0]]\n",
       "Categories (5, interval[float64]): [(-0.001, 1.0] < (1.0, 2.0] < (2.0, 4.0] < (4.0, 10.0] < (10.0, 465.0]]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_posts'],150, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1.0], (1.0, 2.0], (2.0, 636.0]]\n",
       "Categories (3, interval[float64]): [(-0.001, 1.0] < (1.0, 2.0] < (2.0, 636.0]]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_votes'],200, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1.0], (1.0, 46.0]]\n",
       "Categories (2, interval[float64]): [(-0.001, 1.0] < (1.0, 46.0]]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_endorsed'],5000, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1.0], (1.0, 3.0], (3.0, 142.0]]\n",
       "Categories (3, interval[float64]): [(-0.001, 1.0] < (1.0, 3.0] < (3.0, 142.0]]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_threads'],150, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 1.0], (3.0, 444.0], (1.0, 3.0]]\n",
       "Categories (3, interval[float64]): [(-0.001, 1.0] < (1.0, 3.0] < (3.0, 444.0]]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_comments'],100, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 18.0]]\n",
       "Categories (1, interval[float64]): [(-0.001, 18.0]]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_pinned'],100, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.001, 2.0], (22.0, 9192.0], (6.0, 22.0], (2.0, 6.0]]\n",
       "Categories (4, interval[float64]): [(-0.001, 2.0] < (2.0, 6.0] < (6.0, 22.0] < (22.0, 9192.0]]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df_clean['nforum_events'],50, duplicates='drop').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We like the bucketing with the numbers above. It doesnt provide too much granularity such that the bucket is a unique identifier and the buckets themselves seem useful in analysis for educational researchers. Often it comes down to, did this person participate in a forum in a particular way, and did they do it a lot or a little. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generalizes continuous variables using pandas qcut function. Takes list of q values\n",
    "to be passed in applying to the corresponding column\n",
    "\"\"\"\n",
    "def generalizeContinous(df, cols, qs):\n",
    "    df_g = df.copy()\n",
    "    for i in range(0,len(cols)):\n",
    "        df_g[cols[i]] = pd.qcut(df_g[cols[i]], qs[i], duplicates='drop')\n",
    "    return df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cols = ['YoB','nforum_posts','nforum_votes','nforum_endorsed','nforum_threads',\n",
    "'nforum_comments','nforum_pinned','nforum_events']\n",
    "qs = [10,150,200,5000,150,100,100,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = generalizeContinous(df_clean, gen_cols, qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalizing Location Fields by Dropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fields are just too specific. Hence we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen2 = df_gen.drop(columns=['postalCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "qis_gbs = list(set(qis)-set(['postalCode']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-anon dataset completion rate: 1.568%\n",
      "3-anon dataset exploration rate: 11.882%\n",
      "149914 records suppressed for k=3\n"
     ]
    }
   ],
   "source": [
    "df_3gbs = suppressKAnon(df_gen, qis_gbs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(checkKAnon(df_3gbs, qis, 5)), \"k-anonymity only \"+str(getKAnon(df_3gbs,qis_gbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-anon dataset completion rate: 1.512%\n",
      "4-anon dataset exploration rate: 11.834%\n",
      "157720 records suppressed for k=4\n"
     ]
    }
   ],
   "source": [
    "df_4gbs = suppressKAnon(df_gen, qis_gbs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-anon dataset completion rate: 1.503%\n",
      "5-anon dataset exploration rate: 11.678%\n",
      "162892 records suppressed for k=5\n"
     ]
    }
   ],
   "source": [
    "df_5gbs = suppressKAnon(df_gen, qis_gbs, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grade is the sensitive attribute we want to analyze with respect to L-diversity. We will will look at the counts of records that have each grade to do so. We added a new field to the suppression algorithm `l_grades` which counts the amount of unique grades for a given set of quasi-identifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-diversity for 3-anonymous dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"L-diversity for 3-anonymous dataset: \"+str(min(df_3gbs['l_grades'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-diversity for 3-anonymous dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"L-diversity for 4-anonymous dataset: \"+str(min(df_4gbs['l_grades'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-diversity for 5-anonymous dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"L-diversity for 5-anonymous dataset: \"+str(min(df_5gbs['l_grades'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the 3, 4, and 5 had 1-diversity. There simply is not enough unique grade values for each set of quasi-identifiers. Using synthetic records would be a good idea to increase L-diversity as we could add more unique grades for a given set of quasi-identifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
